io: &paths
  subject_id: &id WF_T_21
  data_path: /export01/data/Hanwen/data/mgre_data/WT_F_21/niftis/mgre/mgre_mag_mi_phs_corrected.nii
  mask_path: /export01/data/Hanwen/data/mgre_data/WT_F_21/niftis/mgre/mask.nii
  save_path: results/sled/WT_F_21_mgre_
  save_model_path: &model_path models/best_epoch_WT_F_21.h5

preprocessing:
  mask_threshold: 0.5
  normalization: False
  scaling_quantile: 0.99

model: &structure
  encoder:
    name: encoder model
    input_shape: &num_te 24
    latent_shape: &num_pool 3
    range_t2_my: [0.003, 0.015]
    range_t2_ie: [0.045, 0.07]
    range_t2_fr: [0.2, 0.3]

    # encoder architecture
    base_nn_t2s:
      name: mlp # selections = [mlp, resnet]

    base_nn_amps:
      name: mlp # selections = [mlp, resnet]

    base_mlp_t2:
      hidden_layers: [256, 128]
      num_classes: 1
      activation: sigmoid
      activation_last_layer: sigmoid

    base_mlp_amps:
      hidden_layers: [256, 256]
      num_classes: *num_pool
      activation: sigmoid
      activation_last_layer: sigmoid

    base_resnet_t2: 
      hidden_layers_head: [128]
      num_res_blocks: 2
      res_block_size: [256, 256]
      hidden_layers_tail: [128]
      num_classes: 1
      activation: sigmoid
      activation_last_layer: sigmoid

    base_resnet_amps: 
      hidden_layers_head: [128]
      num_res_blocks: 2
      res_block_size: [256, 256]
      hidden_layers_tail: [128]
      num_classes: *num_pool
      activation: sigmoid
      activation_last_layer: sigmoid
    
  decoder:
    name: decoder_exp
    num_classes: *num_pool
    nte: *num_te
    delta_te: 0.002
    snr_range: [50, 300]


training:
  # model compile
  name: *id
  model_structure: *structure 
  loss_function: mse #categorical_crossentropy
  optimizer:
    name: adamax
    lr: 0.001
    clipnorm: Null
    clipvalue: Null
  metric: mae

  # model training
  shuffle: True
  epochs: 200
  batch_size: 512
  verbose: 1 

  # callbacks
  TensorBoard_log_path: logs
  TensorBoard_hist_freq: 1
  EarlyStopping_monitor: loss
  EarlyStopping_patience: 15
  ReduceLROnPlateau_monitor: loss
  ReduceLROnPlateau_factor: 0.5
  ReduceLROnPlateau_patience: 3
  Checkpoint_monitor: loss
  save_best_only: True

  # paths
  io: *paths
  log_path: logs/training.log
  save_model_path: *model_path


postprocessing:
  mwf_cutoff: 0.04

